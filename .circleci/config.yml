version: 2.1

orbs:
  aws-cli: circleci/aws-cli@3.1.5
  python: circleci/python@2.1.1
  slack: circleci/slack@4.9.3
commands:
  exports:
    steps:
      - run:
          name: "Get git commit short-hash for the current and the previous commit"
          command: |
            # Git hash for the current commit
            echo 'export current_commit=<< pipeline.git.revision >>' >> "$BASH_ENV"
            echo 'export CUR_SHORT_HASH="${current_commit:0:7}"' >> "$BASH_ENV"
            # Git hash for the previous commit
            echo 'export previous_commit=<< pipeline.git.base_revision >>' >> "$BASH_ENV"
            echo 'export PRE_SHORT_HASH="${previous_commit:0:7}"' >> "$BASH_ENV"
      - run:
          name: "Export environment variable"
          command: |
            echo 'export WORKSPACE_DIR="/home/circleci/workspace"' >> "$BASH_ENV"
            echo 'export PROJECT_ROOT_DIR="/home/circleci/project"' >> "$BASH_ENV"
            echo 'export TEMPLATE_ROOT_DIR="project-3-udacity"' >> "$BASH_ENV"
            echo 'export PROJECT_TAG="tuancnh-Udacity-final-project-3"' >> "$BASH_ENV"
  revert-migrations:
    description: Revert the last migration
    parameters:
      migrations-key:
        type: string
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            cd ~/project/backend
            npm install
  destroy_environment:
    parameters:
      stack_name:
        type: string
      bucket_name:
        type: string
        default: ""
      when:
        default: "on_fail"
        type: enum
        enum: [ "always", "on_success", "on_fail" ]
      aws-access-key-id:
        default: AWS_ACCESS_KEY_ID
        description: >
          AWS access key id for IAM role. Set this to the name of
          the environment variable you will use to hold this
          value, i.e. AWS_ACCESS_KEY.
        type: env_var_name
      aws-region:
        default: AWS_DEFAULT_REGION
        description: >
          Env var of AWS region to operate in
          (defaults to AWS_DEFAULT_REGION)
        type: env_var_name
      aws-secret-access-key:
        default: AWS_SECRET_ACCESS_KEY
        description: >
          AWS secret key for IAM role. Set this to the name of
          the environment variable you will use to hold this
          value, i.e. AWS_SECRET_ACCESS_KEY.
        type: env_var_name
      profile-name:
        default: default
        description: Profile name to be configured.
        type: string
    steps:
      - run:
          name: "Install AWS CLI"
          when: << parameters.when >>
          command: |
            if aws --version | grep "aws-cli/" > /dev/null
            then
              echo "AWS CLI is already installed, skipping installation."
              exit 0
            fi
            
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
      - run:
          name: "Configure AWS credential"
          environment:
            PARAM_AWS_CLI_ACCESS_KEY_ID: <<parameters.aws-access-key-id>>
            PARAM_AWS_CLI_SECRET_ACCESS_KEY: <<parameters.aws-secret-access-key>>
            PARAM_AWS_CLI_REGION: <<parameters.aws-region>>
            PARAM_AWS_CLI_PROFILE_NAME: <<parameters.profile-name>>
          when: << parameters.when >>
          command: |
            if aws --version | grep "aws-cli/" > /dev/null
            then
              echo "Due to AWS CLI is already installed, skipping configuration AWS credential."
              exit 0
            fi
            
            PARAM_AWS_CLI_ACCESS_KEY_ID=$(eval echo "\$$PARAM_AWS_CLI_ACCESS_KEY_ID")
            
            PARAM_AWS_CLI_SECRET_ACCESS_KEY=$(eval echo "\$$PARAM_AWS_CLI_SECRET_ACCESS_KEY")
            
            PARAM_AWS_CLI_REGION=$(eval echo "\$$PARAM_AWS_CLI_REGION")
            
            if [ -z "$PARAM_AWS_CLI_ACCESS_KEY_ID" ] || [ -z "${PARAM_AWS_CLI_SECRET_ACCESS_KEY}" ]
            then
              echo "Cannot configure profile. AWS access key id and AWS secret access key must be provided."
              exit 1
            fi
            
            aws configure set \
              aws_access_key_id "$PARAM_AWS_CLI_ACCESS_KEY_ID" \
              --profile "$PARAM_AWS_CLI_PROFILE_NAME"
            
            aws configure set \
              aws_secret_access_key "$PARAM_AWS_CLI_SECRET_ACCESS_KEY" \
              --profile "$PARAM_AWS_CLI_PROFILE_NAME"
            
            aws configure set \
              region "$PARAM_AWS_CLI_REGION" \
              --profile "$PARAM_AWS_CLI_PROFILE_NAME"
      - run:
          name: "Empty << parameters.bucket_name >> bucket"
          when: << parameters.when >>
          shell: /bin/bash
          command: |
            bucket_name="<< parameters.bucket_name >>"
            
            if [[ -z $bucket_name ]]
            then
              echo "Skip the empty bucket action due to the empty bucket name"
              exit 0
            fi
            
            bucket_uri="s3://$bucket_name"
            bucket_info=$(aws s3 ls $bucket_uri 2>&1)
            
            if echo $bucket_info | grep 'NoSuchBucket' > /dev/null
            then
              echo "Bucket doesn't exist, skip the empty bucket action"
              exit 0
            fi
            
            # Empty before delete the bucket
            aws s3 rm $bucket_uri --recursive
      - run:
          name: "Delete << parameters.stack_name >> stack"
          when: << parameters.when >>
          shell: /bin/bash
          command: |
            # Get stack id for the delete_stack waiter
            stack_info=$(aws cloudformation describe-stacks --stack-name << parameters.stack_name >> --query "Stacks[*] | [0].StackId" 2>&1)
            if echo $stack_info | grep 'does not exist' > /dev/null
            then
              echo "Stack does not exist."
              echo $stack_info
              exit 0
            fi
            if echo $stack_info | grep 'ValidationError' > /dev/null
            then
              echo $stack_info
              exit 1
            else
              aws cloudformation delete-stack --stack-name << parameters.stack_name >>
              echo $stack_info
              aws cloudformation wait stack-delete-complete --stack-name $stack_info
              if [ "<< parameters.when >>" = "on_fail" ]
              then
                echo "Roll back completed. Green environment destroyed."
                exit 0
              fi
              echo "Stack << parameters.stack_name >> cleaned up"
              exit 0
            fi
jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build frontend
          command: |
            pwd
            ls
            ls $(eval echo "$CIRCLE_WORKING_DIRECTORY")
            cd $(eval echo "$PROJECT_ROOT_DIR/frontend")
            npm install
            npm run build --force
      - save_cache:
          paths: [/home/circleci/project/frontend/node_modules]
          key: frontend-build
  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - restore_cache:
          keys: [ backend-build ]
      - run:
          name: Save all db varibles in env file
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/backend")
            touch .env
            echo NODE_ENV=production >> .env
            echo TYPEORM_HOST=$TYPEORM_HOST >> .env
            echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> .env
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> .env
            echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> .env
            echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> .env
            echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> .env
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> .env
            echo TYPEORM_PORT=$TYPEORM_PORT >> .env
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> .env
      - run:
          name: Build backend
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/backend")
            npm install
            npm run build
            cd ..
            # Compress the backend folder
            tar -C backend -czvf artifact-backend.tar.gz .
            # no error if existing, make parent directories as needed
            mkdir --parents $WORKSPACE_DIR
            # Move the compressed file to workspace folder
            mv artifact-backend.tar.gz $WORKSPACE_DIR/artifact-backend.tar.gz
      - persist_to_workspace:
          root: /home/circleci/workspace
          paths:
            - "artifact-backend.tar.gz"
      - save_cache:
          paths: [ /home/circleci/project/backend/node_modules ]
          key: backend-build

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    # Docker image here that supports AWS CLI
    steps:
      - checkout
      # Export environment variable
      - exports
      # Set up AWS Credentials
        # Create backend infrastructure
      # Checkout code from git
      - run:
          name: Install tar utility
          command: |
            yum install -y tar gzip
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            pwd
            ls
            ls $(eval echo "$CIRCLE_WORKING_DIRECTORY")
            aws cloudformation deploy \
              --template-file backend.yml \
              --tags project=project-3-backend \
              --stack-name Udapeople-Backend-${CIRCLE_WORKFLOW_ID:0:5} \
              --region us-east-1 \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:5}"
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file frontend.yml \
              --tags project=project-3-frontend \
              --stack-name Udapeople-Frontend-${CIRCLE_WORKFLOW_ID:0:5} \
              --region us-east-1 \
              --parameter-overrides MyBucketName="bucket-${CIRCLE_WORKFLOW_ID:0:5}"
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text
            aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - project/inventory.txt

  add_publicipaddress_to_inventory:
    docker:
      - image: amazon/aws-cli
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      - exports
      - run:
          name: Install tar utility
          command: |
            yum install -y tar gzip
      - run:
          name: "Get EC2 Instances Public IP Address"
          command: |
            cd ~/project/
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:project,Values=project-3-backend" \
            --output text >> inventory
      - run:
          name: "Move inventory file into workspace"
          command: |
            cd ~/project/
            mv inventory ~/inventory
      - persist_to_workspace:
          root: ~/
          paths:
            - "inventory"

  configure-infrastructure:
    docker:
      - image: python:3.10.10-alpine3.17
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["f4:85:15:29:15:71:41:1a:de:65:52:b8:5b:3b:0e:1b"]
      - run:
          name: "Install Ansible"
          command: |
            apk add --update ansible
      - attach_workspace:
          at: ~/
      - run:
          name: Run Playbook and Configure server
          command: |
            cd ~/project/
            ansible-playbook -i ~/inventory main.yml --ssh-common-args='-o StrictHostKeyChecking=no'

  run-migrations:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - run:
          name: Run migrations
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/backend")
            npm install
            echo $(eval echo "$TYPEORM_HOST")
            echo $(eval echo "TYPEORM_PORT")
            echo $(eval echo "TYPEORM_USERNAME")
            nc -zv database-2.cej6qdae1a10.us-east-1.rds.amazonaws.com 5432
            npm run migrations > migrations_dump.txt
      - run:
          name: Send migration results to memstash
          command: |
            npm install 
            if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
            then
              curl -H "Content-Type: text/plain" -H "token: 7933fe63-4687-4fa1-8426-aa25aa1730ec" --request PUT --data "1" https://api.memstash.io/values/migration_${CIRCLE_WORKFLOW_ID:0:7}
            fi

  deploy-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - exports
      - run:
          name: "Install AWS CLI"
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
      - run:
          name: Get backend url
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/frontend")
            touch .env
            export BACKEND_IP=$(aws ec2 describe-instances --query Reservations[*].Instances[*].PublicIpAddress --filters Name=tag:project,Values=project-3-backend --output text)
            export API_URL="http://${BACKEND_IP}:3030"
            echo "API_URL = ${API_URL}"
            echo API_URL="http://${BACKEND_IP}:3030" >> .env
            npm install
            npm run build 
            tar -czvf "artifact-$CUR_SHORT_HASH.tar.gz" dist
            aws s3 sync dist s3://bucket-91019 --delete
  deploy-backend:
    executor:
      name: python/default
      tag: "3.11.2"
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - add_ssh_keys:
          fingerprints: ["f4:85:15:29:15:71:41:1a:de:65:52:b8:5b:3b:0e:1b"]
      - python/install-packages:
          args: ansible
      - attach_workspace:
          at: /home/circleci/workspace
      - run:
          name: "Install AWS CLI"
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
      - run:
          name: Deploy backend
          command: |
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:project,Values=project-3-backend" \
            --output text >> $(eval echo "$CIRCLE_WORKING_DIRECTORY/.circleci/ansible/inventory")
            # Move the compressed file to ansible folder
            # no error if existing, make parent directories as needed
            mkdir --parents $(eval echo "$CIRCLE_WORKING_DIRECTORY/.circleci/ansible/roles/deploy/files")
            mv $WORKSPACE_DIR/artifact-backend.tar.gz $(eval echo "$CIRCLE_WORKING_DIRECTORY/.circleci/ansible/roles/deploy/files/artifact-backend.tar.gz")
      - run:
          name: "Ansible play book for deploy backend"
          command: |
            ansible-playbook -i $(eval echo "$CIRCLE_WORKING_DIRECTORY/.circleci/ansible/inventory") $(eval echo "$CIRCLE_WORKING_DIRECTORY/.circleci/ansible/deploy-backend.yml")

  smoke-test:
    executor: aws-cli/default
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      # Set up AWS Credentials
      - aws-cli/setup
      - attach_workspace:
          at: /home/circleci/workspace
      - run:
          name: Frontend smoke test.
          command: |
            URL="http://bucket-91019.s3-website-us-east-1.amazonaws.com/#/employees"            
            echo ${URL} 
            test_result=$(curl -s "$URL")
            if echo $test_result | grep "Welcome" > /dev/null
            then
              echo "Frontend test passed"
              echo $test_result
              exit 0
            else
              echo $test_result
              exit 1
            fi
      - run:
          name: "Backend smoke test"
          command: |
            export BACKEND_IP=$(aws ec2 describe-instances --query Reservations[*].Instances[*].PublicIpAddress --filters Name=tag:project,Values=project-3-backend --output text)
            export API_URL="http://${BACKEND_IP}:3030"
            echo "${API_URL}"
            curl --version
            # When the backend server is not ready, let retry upto 30mins
            test_result=$(eval curl \
              --verbose --fail \
              --retry 360 --retry-max-time 1800 --retry-all-errors \
              --url "$API_URL/api/status")
            if echo $test_result | grep "ok" > /dev/null
            then
              echo "Backend test passed"
              echo $test_result
              exit 0
            else
              echo $test_result
              exit 1
            fi
      # Rollback if fail
      - revert-migrations:
          migrations-key: migration_${CIRCLE_WORKFLOW_ID:0:5}
      - destroy_environment:
          stack_name: Udapeople-Frontend-${CIRCLE_WORKFLOW_ID:0:5}
          bucket_name: bucket-${CIRCLE_WORKFLOW_ID:0:5}
      - destroy_environment:
          stack_name: Udapeople-Backend-${CIRCLE_WORKFLOW_ID:0:5}

  promote-to-production:
    docker:
      - image: amazon/aws-cli
    # Docker image here that supports AWS CLI
    steps:
      - checkout
      - exports
      - run:
          name: Install tar utility
          command: |
            yum install -y tar gzip
      - run:
          name: "Get EC2 Instances Public IP Address"
          command: |
            pwd
            ls
            ls $(eval echo "$CIRCLE_WORKING_DIRECTORY")
            aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name InitialStack \
              --parameter-overrides WorkflowID="udapeople-${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=udapeople
      # Rollback if fail
      - revert-migrations:
          migrations-key: migration_$CUR_SHORT_HASH
      - destroy_environment:
          stack_name: Udapeople-Frontend-${CIRCLE_WORKFLOW_ID:0:5}
          bucket_name: bucket-${CIRCLE_WORKFLOW_ID:0:5}
      - destroy_environment:
          stack_name: Udapeople-Backend-${CIRCLE_WORKFLOW_ID:0:5}

  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Test frontend
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/frontend")
            npm install
            npm run test
  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      - restore_cache:
          keys: [ backend-build ]
      - run:
          name: Test backend
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/backend")
            npm install
            npm run test

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      # Restore from cache
      - restore_cache:
          keys: [frontend-build]
      # Your job code here
      - run:
          name: "Scan frontend"
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/frontend")
            npm audit fix --audit-level=critical --force
            # If the "npm audit fix" command above could not fix all critical vulnerabilities, try “npm audit fix --force” again
            npm audit fix --force
            npm audit --audit-level=critical
  scan-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      # This command will pull all of the files into a directory called project which can be found at ~/project.
      - checkout
      # Export environment variable
      - exports
      # Restore from cache
      - restore_cache:
          keys: [backend-build]
      # Your job code here
      - run:
          name: "Scan backend"
          command: |
            cd $(eval echo "$PROJECT_ROOT_DIR/backend")
            npm audit fix --audit-level=critical --force
            # If the "npm audit fix" command above could not fix all critical vulnerabilities, try “npm audit fix --force” again
            npm audit fix --force
            npm audit --audit-level=critical
  notify:
    docker:
      - image: cimg/base:stable
    steps:
      - slack/notify:
          custom: |
            {
              "text": "",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "❌ *Failure* #${CIRCLE_BUILD_NUM} `${CIRCLE_PROJECT_REPONAME}` on `${CIRCLE_BRANCH}`"
                  }
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Job"
                      },
                      "url": "${CIRCLE_BUILD_URL}"
                    }
                  ]
                }
              ]
            }
          event: always

workflows:
  my-workflow:
    jobs:
      - smoke-test
      - promote-to-production:
          requires: [smoke-test]


